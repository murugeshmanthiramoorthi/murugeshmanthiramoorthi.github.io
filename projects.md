---
layout: page
title: Projects

---

Here you can check all of my pet projects which allowed me to experiment with the knowledge acquired though various MOOCs and books.I have updated some of them here. 

---

# Featured Projects
---

#### Preludd Data Challenge
* Analyzed and categorized customers based on their transactional behavior and demographic factors into different payment profiles
* Built real-time dashboards to explain current payment profiles and recommend Alternative Payments Methods as part of Digital Transformation 
* Developed a python application to view the summary of the transactions data based on the selected filters

**TOOLS USED**: Jupyter Notebook, Python, Dataiku DSS, Tableau Desktop, Streamlit

![Projects](/assets/img/projects/preludd.png "Preludd Data Challenge")

---
#### Musée d'Orsay and Musée de l'Orangerie - Data Vizualization Challenge
* Combined data from various resources, cleaned them and enriched them using various tools abnd techniques
* Analysed the cleaned data to find lot of useful trens abd patterns to recommend solutions and improvements
* Performed web scraping of Trip Advisor reviews to observe what people speak about Musée d'Orsay and Musée de l'Orangerie

**TOOLS USED**: Tableau Desktop, Tableau Prep, RStudio, Jupyter Notebook, MS Excel

![Projects](/assets/img/projects/musee.png "Musée d'Orsay and Musée de l'Orangerie - Data Vizualization Challenge")

---
#### Netflix Recommendation System
* Developed a movie recommendation system for Netflix in R using two different approaches (User-Based Collobarative Filtering and Matrix Factorization)
* Evaluated the performance of two recommendation systems using ROC Curve and accuracy
* Built prototypes of the recommendation systems using R shiny with a convenient User Interface

**TOOLS USED**: R, RStudio, Tableau Desktop

![Projects](/assets/img/projects/netflix.png "Netflix Recommendation System")

---

# Other Projects
---


#### Walton Analytics - Product Performance and Consumer Behavior Dashboard
* Merged data from different possible sources, cleaned the data and enriched it using Tableau Prep Builder
* Performed cohort analysis on the sales data to track the movement and flow of customers between differenmt quarters
* Perfomed RFM analysis to segment the customers into 5 different categories based on the managerial comfort and explored their overall profile
* Computed Customer Lifetime Value of all the customers and projevcted it to next 6 years based on the consumer behavior and their churn rate

**TOOLS USED**: Tableau Desktop, Tableau Prep Builder, RStudio

---
#### Baker's Database Analysis for HR
* Developed SQL queries for the requirements by HR from an employee database of 7 different tables and arouns 3 million entries
* Derived insights from the extracted data using Tableau Desktop to provide recommendations to the HR
* Provided recommendations to improve employee retainment in the company

**TOOLS USED**: MySQL Workbench, Tableau Desktop

---
#### CDiscount - Data Vizualization
* Cleaned and enriched the dataset using Tableau Prep Builder
* Compared the sales trend of CDiscount in France with other countries
* Explored the data, found the profit generating products and loss creating products
* Followed almost all the data visualization principles to obtain clutter free, clear data viz

**TOOLS USED**: Tableau Desktop, Tableau Prep Builder

---
#### Embracing Subcultures - The success of Burger King
* Performed a case study on the series of marketing campaigns by Burger King over years embracing the subcultures existing within their customer profiles
* Researched the different kinds of subcultures they have utilized and the response among their customers
* Developed different methodologies on how they would have utilized the power of big data to perform these tasks

**TOOLS USED**: Google Sheets, Google Slides

---
#### Quora Duplicate Question prediction
* Repeated questions are one of the greatest complications of Quora. It leads to confusion and poor reach
* I processed the data using TF-IDF vectorizer and fit the model on various classification models
* Conventional logistic regression seem to give better solutions

**TOOLS USED**: Sklearn, pandas, numpy

---
#### Whatsapp Frequent Chat analysis
* Developed a model which can analyze whatsapp chats and deliver us valuable insights
* Determined the frequently used words, most active days and most active time of the day
* Working on determining the sentiment of chat and predicting the relationship based on the chat

**TOOLS USED**: Sklearn, pandas, numpy, matplotlib

---
#### Heart disease prediction
* Trained a ML model to predict the possibility of occurance of heart disease for a person based on his demographic attributes
* Some of the features used include cholestrol level, age, weight, gender, heart beat rate etc. and achieved 85% accuracy on the validation set

**TOOLS USED**: sklearn, numpy, pandas, seaborn

---
#### Tourism data analyis
* Performed data analysis on the world tourism data using SAS to uncover some hidden facts
* Found out the countries with maximum share of tourism attraction, country which generates maximum revenue, country which spends the maximum on tourism industry
* TOOLS USED: SAS

---
#### Malaria detection from microscope images
* Trained and improved the performance of a CNN architecture using various image augmentation techniques and optimizers
* Achieved an training and validation accuracy of both 94.5%

**TOOLS USED**: Keras, pickle, numpy, matplotlib

---
#### Digit recognizer web application
* Trained a custom developed CNN architecture to train on MNIST dataset
* The model is then served using flask to predict the digits on local server

**TOOLS USED**: Keras, pickle, numpy

---
#### Stackoverflow pragramming language classification
* Used questions and its respective programming lanuages to train a machine learning model with TF-IDF vectorizer 
* Achieved 92% accuracy on predicting the programming langauge given its questions.

**TOOLS USED**: sklearn, scipy, NLTK, pandas

---
#### Cat vs no-cat classifier
* Trained a CNN model to predict between cats and non-cats images
* The model achieved a 91% accuracy in identifying 

**TOOLS USED**: Keras, pickle, numpy

---
#### Text exploration using Topic Modelling
* Performed Topic modelling on a set of documents using LSA, LDA and NMF with available packages
* Implemented topic modelling papeers such as PAM, pLSA in python

**TOOLS USED**: sklearn, pandas, numpy, scipy

---
#### Indian Restaurant Market Analysis
* Preprocessd and feature engineered the data on Indian Restaurants spread across various cities
* Fit a model to determine the overall rating based on the most relevant features

**TOOLS USED**: dplyr, ggplot2

---
#### Customer Churn Prediction
* Exploed the data to detremine the significant features among the given features
* Model is fit using classification methods and the results are compared

**TOOLS USED**: Sklearn, pandas, numpy, matplotlib, seaborn

---
#### Design of Front and Rear Suspension Geometry for All-terrain vehicles
* Unequal Unparallel double wishbone system and H arm with camber link suspension system has been for Front and Rear Suspension Geometry respectively based on the design considerations
* The system is designed using Solidworks and is analysed using ANSYS and MATLAB

**TOOLS USED**: Solidworks, ANSYS, Lotus Shark

---
#### Development of Part Identification System of Baja vehicle components
* In a single baja vehicle more than 500 components are being used. Unnecessary time is used for searching different components during assembly
* So, various components are named using Hybrid Part Identification systems and are grouped together based on the frequency of usage
* This decreased the time consumption by many folds

**TOOLS USED**: MS Excel

---
#### Optimisation of Front and Rear Uprights for All-terrain vehicles
* Based on the load applied and fatigue life, structural design and sectional thickness has been modified to minimise the material usage without trading off the steering performance of the vehicle
* Final design is chosen based upon a number of iterations results and in accordance with suspension parameters too 

**TOOLS USED**: Solidworks, ANSYS

---
#### Intelligent Anti-theft System for Two Wheelers
* Incase, if a two wheeler is attempted or subjected to theft, our installed set-up captures the snap of the intruder and sends the snap to the owner's phone along with the dynamic GPS coordinates of the two wheeler using GSM

**TOOLS USED**: Arduino UNO R3

---
#### Design and Analysis of Hydrogen Propelled Mobility Vehicle
* A parallel hybrid two wheeler powered by both Li polymer battery with a rated capacity of 20Ah (based on our requirement) and PEMFC has been modeled with custom designed chassis, suspension, brakes and storage tank. 
* Material for each component has been chosen from numerous analysis of the components’ solid model. 
* Pedal force, brake force distribution, stopping distance and brake power are calculated theoretically. 
* With a fixed wheel base of 1.32m and load distribution calculated based on brake power, all the suspension parameters such as motion ratio, corner weight, wheel rate, spring rate are calculated. 
* These parameters are optimized using MS Excel and Matlab Simulink. 
* The chassis body dimensions and cross sections are chosen based on Taguchi method. 
* Real effort has been taken to measure the real dimensions of the chassis based on the ergonomic comfort of many persons of distributed age and size.

**TOOLS USED**: Soliworks, ANSYS, Minitab, Matlab Simulink, MS Excel

---
#### Design and Analysis of on-board high pressure compressed hydrogen storage tank
* After finalizing the hybrid vehicle architecture and storage pressure of 700 bar, power required to propel a payload of 180 kg was calculated. 
* Comparing the heat of combustion of hydrogen and the energy needed to be produced, the mass of hydrogen required is calculated to be 1.2 kg. 
* Volume of hydrogen required is calculated and compared by Ideal gas equation, van Der Wall’s equation and generalized comparability chart. 
* A triple composite layer tank is chosen with specific dimensions after numerous iterations on ANSYS. 
* Finally, analytical simulation of burst test, crush test is carried out on the final model to ensure its endurance

**TOOLS USED**: Soliworks, ANSYS, Matlab Simulink, MS Excel

---
